{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac460ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing data: 100%|██████████| 1228/1228 [00:00<00:00, 2391.02it/s]\n",
      "Preparing data: 100%|██████████| 154/154 [00:00<00:00, 4268.25it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ujson\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from sentence_transformers import CrossEncoder, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --------- Configuration ---------\n",
    "DATA_DIR = Path(\"data\")\n",
    "TRAIN_FN = DATA_DIR / \"train-claims-top100.json\"\n",
    "DEV_FN = DATA_DIR / \"dev-claims-top100.json\"\n",
    "TEST_FN = DATA_DIR / \"test-claims-top100.json\"\n",
    "\n",
    "MODEL_NAME = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "TOP_M = 6\n",
    "CHECKPOINT_DIR = DATA_DIR / \"checkpoints\"\n",
    "FINAL_MODEL_DIR = DATA_DIR / \"fine-tuned-model\"\n",
    "\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "FINAL_MODEL_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# --------- Prepare Training Data ---------\n",
    "def load_claim_texts(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        data = ujson.load(f)\n",
    "    return {cid: (item[\"claim_text\"] if isinstance(item, dict) else item) for cid, item in data.items()}\n",
    "def load_groundtruth_evidence(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        data = ujson.load(f)\n",
    "    gt = {}\n",
    "    for cid, details in data.items():\n",
    "        if isinstance(details, dict):\n",
    "            gt[cid] = set(details.get(\"evidences\", []))\n",
    "        else:\n",
    "            gt[cid] = set()\n",
    "    return gt\n",
    "\n",
    "def prepare_training_data(top100_path, claims_path, gt_evidence, evidences):\n",
    "    with open(top100_path, encoding='utf-8') as f:\n",
    "        top100 = ujson.load(f)\n",
    "    claims = load_claim_texts(claims_path)\n",
    "\n",
    "    examples = []\n",
    "    for cid, entry in tqdm(top100.items(), desc=\"Preparing data\"):\n",
    "        claim = claims.get(cid, \"\")\n",
    "        cand_ids = entry[\"evidences\"] if isinstance(entry, dict) else entry\n",
    "        gt_evid = gt_evidence.get(cid, set())\n",
    "\n",
    "        for eid in cand_ids:\n",
    "            label = 1.0 if eid in gt_evid else 0.0\n",
    "            examples.append(InputExample(texts=[claim, evidences[eid]], label=label))\n",
    "\n",
    "    return examples\n",
    "\n",
    "# Load evidences\n",
    "with open(DATA_DIR / \"evidence.json\", encoding='utf-8') as f:\n",
    "    evid_dict = ujson.load(f)\n",
    "\n",
    "# Ground truth evidence\n",
    "train_gt = load_groundtruth_evidence(DATA_DIR / \"train-claims.json\")\n",
    "dev_gt = load_groundtruth_evidence(DATA_DIR / \"dev-claims.json\")\n",
    "\n",
    "# Training and Dev data\n",
    "train_examples = prepare_training_data(TRAIN_FN, DATA_DIR / \"train-claims.json\", train_gt, evid_dict)\n",
    "dev_examples = prepare_training_data(DEV_FN, DATA_DIR / \"dev-claims.json\", dev_gt, evid_dict)\n",
    "\n",
    "# --------- Fine-tuning Cross-Encoder ---------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CrossEncoder(MODEL_NAME, num_labels=1, device=device)\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=BATCH_SIZE)\n",
    "loss_fn = losses.MSELoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac8c1add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import SentenceEvaluator\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "class CustomCrossEncoderEvaluator(SentenceEvaluator):\n",
    "    def __init__(self, examples, name=\"\"):\n",
    "        self.examples = examples\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, model, output_path=None, epoch=-1, steps=-1):\n",
    "        texts = [example.texts for example in self.examples]\n",
    "        labels = [example.label for example in self.examples]\n",
    "\n",
    "        preds = model.predict(texts)\n",
    "        preds_binary = (np.array(preds) > 0.5).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(labels, preds_binary)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds_binary, average='binary')\n",
    "\n",
    "        print(f\"\\n[{self.name} Evaluation] Epoch {epoch}, Step {steps}:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "        # Returning F1 for save_best_model criterion\n",
    "        return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae93536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11514' max='11514' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11514/11514 17:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Evaluator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.126316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.101449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.156463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.080586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.221538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.144828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.155932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.226300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.271003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.201780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[dev Evaluation] Epoch 0.26055237102657636, Step 1000:\n",
      "Accuracy: 0.9919, Precision: 0.6429, Recall: 0.0700, F1: 0.1263\n",
      "\n",
      "[dev Evaluation] Epoch 0.5211047420531527, Step 2000:\n",
      "Accuracy: 0.9919, Precision: 0.7368, Recall: 0.0545, F1: 0.1014\n",
      "\n",
      "[dev Evaluation] Epoch 0.7816571130797291, Step 3000:\n",
      "Accuracy: 0.9919, Precision: 0.6216, Recall: 0.0895, F1: 0.1565\n",
      "\n",
      "[dev Evaluation] Epoch 1.0, Step 3838:\n",
      "Accuracy: 0.9920, Precision: 0.6774, Recall: 0.0817, F1: 0.1458\n",
      "\n",
      "[dev Evaluation] Epoch 1.0422094841063054, Step 4000:\n",
      "Accuracy: 0.9919, Precision: 0.6875, Recall: 0.0428, F1: 0.0806\n",
      "\n",
      "[dev Evaluation] Epoch 1.3027618551328817, Step 5000:\n",
      "Accuracy: 0.9918, Precision: 0.5294, Recall: 0.1401, F1: 0.2215\n",
      "\n",
      "[dev Evaluation] Epoch 1.563314226159458, Step 6000:\n",
      "Accuracy: 0.9919, Precision: 0.6364, Recall: 0.0817, F1: 0.1448\n",
      "\n",
      "[dev Evaluation] Epoch 1.8238665971860344, Step 7000:\n",
      "Accuracy: 0.9919, Precision: 0.6053, Recall: 0.0895, F1: 0.1559\n",
      "\n",
      "[dev Evaluation] Epoch 2.0, Step 7676:\n",
      "Accuracy: 0.9918, Precision: 0.5283, Recall: 0.1089, F1: 0.1806\n",
      "\n",
      "[dev Evaluation] Epoch 2.084418968212611, Step 8000:\n",
      "Accuracy: 0.9918, Precision: 0.5286, Recall: 0.1440, F1: 0.2263\n",
      "\n",
      "[dev Evaluation] Epoch 2.344971339239187, Step 9000:\n",
      "Accuracy: 0.9910, Precision: 0.4138, Recall: 0.1868, F1: 0.2574\n",
      "\n",
      "[dev Evaluation] Epoch 2.6055237102657633, Step 10000:\n",
      "Accuracy: 0.9913, Precision: 0.4464, Recall: 0.1946, F1: 0.2710\n",
      "\n",
      "[dev Evaluation] Epoch 2.8660760812923396, Step 11000:\n",
      "Accuracy: 0.9913, Precision: 0.4250, Recall: 0.1323, F1: 0.2018\n",
      "\n",
      "[dev Evaluation] Epoch 3.0, Step 11514:\n",
      "Accuracy: 0.9913, Precision: 0.4421, Recall: 0.1634, F1: 0.2386\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune\n",
    "dev_evaluator = CustomCrossEncoderEvaluator(dev_examples, name=\"dev\")\n",
    "\n",
    "model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    evaluator=dev_evaluator,\n",
    "    evaluation_steps=1000,\n",
    "    warmup_steps=int(0.1 * len(train_dataloader) * NUM_EPOCHS),\n",
    "    output_path=str(FINAL_MODEL_DIR),\n",
    "    save_best_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289eb330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|██████████| 153/153 [00:12<00:00, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --------- Rerank Test Set ---------\n",
    "model = CrossEncoder(str(FINAL_MODEL_DIR), device=device)\n",
    "\n",
    "def rerank_and_save(top100_path, claims_path, evidences, out_dense_path, out_text_path):\n",
    "    with open(top100_path, encoding='utf-8') as f:\n",
    "        top100 = ujson.load(f)\n",
    "    claims = load_claim_texts(claims_path)\n",
    "\n",
    "    dense_out = {}\n",
    "    text_out = {}\n",
    "\n",
    "    for cid, entry in tqdm(top100.items(), desc=\"Reranking\"):\n",
    "        cand_ids = entry[\"evidences\"] if isinstance(entry, dict) else entry\n",
    "        claim = claims.get(cid, \"\")\n",
    "        pairs = [(claim, evidences[eid]) for eid in cand_ids]\n",
    "\n",
    "        scores = model.predict(pairs, batch_size=BATCH_SIZE)\n",
    "\n",
    "        top_idx = scores.argsort()[-TOP_M:][::-1]\n",
    "        top_ids = [cand_ids[i] for i in top_idx]\n",
    "\n",
    "        dense_out[cid] = top_ids\n",
    "        text_out[cid] = {\n",
    "            \"claim_text\": claim,\n",
    "            \"ranked_evidences\": [{\"id\": eid, \"text\": evidences[eid]} for eid in top_ids]\n",
    "        }\n",
    "\n",
    "    with open(out_dense_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(dense_out, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    with open(out_text_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(text_out, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "rerank_and_save(\n",
    "    TEST_FN,\n",
    "    DATA_DIR / \"dev-claims.json\",\n",
    "    evid_dict,\n",
    "    DATA_DIR / f\"dev-claims-top{TOP_M}-dense-fce.json\",\n",
    "    DATA_DIR / f\"dev-claims-top{TOP_M}-text-fce.json\"\n",
    ")\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
